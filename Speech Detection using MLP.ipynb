{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DLHW1P2.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "lTwfLkUveJzX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a = []\n",
        "while(1):\n",
        "    a.append('1')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tptG_Cj2Tidb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -U -q kaggle\n",
        "!mkdir ~/.kaggle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQwPTryxmvsh",
        "colab_type": "code",
        "outputId": "a8da204e-ce44-4648-f421-1d812d24ea70",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 91
        }
      },
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-2fd40e59-fddd-4337-839a-454feb2a16aa\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-2fd40e59-fddd-4337-839a-454feb2a16aa\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"nikunjgoel\",\"key\":\"4d4b8ceb591a64c1ae4e80996446b150\"}'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g06YviLwUjh_",
        "colab_type": "code",
        "outputId": "7da377c9-48db-44e0-c620-cb39b97f365d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "!mv kaggle.json /root/.kaggle/\n",
        "!chmod 600 /root/.kaggle/kaggle.json\n",
        "!kaggle competitions download -c 11-785-s20-hw1p2"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
            "Downloading dev_labels.npy.zip to /content\n",
            "  0% 0.00/381k [00:00<?, ?B/s]\n",
            "100% 381k/381k [00:00<00:00, 52.9MB/s]\n",
            "Downloading train_labels.npy.zip to /content\n",
            "100% 8.40M/8.40M [00:00<00:00, 64.9MB/s]\n",
            "\n",
            "Downloading test.npy.zip to /content\n",
            " 95% 73.0M/76.8M [00:00<00:00, 63.9MB/s]\n",
            "100% 76.8M/76.8M [00:00<00:00, 131MB/s] \n",
            "Downloading train.npy.zip to /content\n",
            "100% 5.16G/5.17G [01:42<00:00, 58.9MB/s]\n",
            "100% 5.17G/5.17G [01:42<00:00, 53.9MB/s]\n",
            "Downloading dev.npy.zip to /content\n",
            " 97% 225M/232M [00:08<00:00, 36.3MB/s]\n",
            "100% 232M/232M [00:08<00:00, 29.8MB/s]\n",
            "Downloading hw1p2_sample_submission.csv.zip to /content\n",
            "  0% 0.00/756k [00:00<?, ?B/s]\n",
            "100% 756k/756k [00:00<00:00, 239MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "44qFKNHEU8R-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "trainingFilePath = \"/content/train.npy.zip\"\n",
        "data_train = np.load(trainingFilePath,encoding = 'bytes',allow_pickle = True)['train']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYztsqGXspgX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainingLabelFilePath = \"/content/train_labels.npy.zip\"\n",
        "data_train_label = np.load(trainingLabelFilePath,encoding = 'bytes',allow_pickle = True)['train_labels']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDi-yM9f3OMT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "testingFilePath = \"/content/test.npy.zip\"\n",
        "data_test = np.load(testingFilePath,encoding = 'bytes',allow_pickle = True)['test']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AA99DafOtVaq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import sys\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "from torch.utils import data\n",
        "from torchvision import transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GL_YmwmKtrm6",
        "colab_type": "code",
        "outputId": "fb4356af-8ef8-4ee4-e4f3-d2b4eeec8364",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cuda = torch.cuda.is_available()\n",
        "cuda"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KRNYRuYddW7E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MyDataset(data.Dataset):\n",
        "    def __init__(self, X, Y):\n",
        "        self.X = torch.from_numpy(np.vstack(X))\n",
        "        self.Y = torch.from_numpy(np.vstack(np.array([np.expand_dims(i,axis=1) for i in Y]))).reshape(self.X.shape[0],)\n",
        "        self.frameIndex = dict()\n",
        "        counter = 0\n",
        "        for i in range(X.shape[0]):\n",
        "          for j in range(X[i].shape[0]):\n",
        "            if j < 12:\n",
        "              self.frameIndex[counter] = j - 12\n",
        "            elif j >= (X[i].shape[0] - 12):\n",
        "              self.frameIndex[counter] =  13 - (X[i].shape[0] - j)\n",
        "            else:\n",
        "              self.frameIndex[counter] = 0\n",
        "            counter = counter + 1 \n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.frameIndex)\n",
        "\n",
        "    def __getitem__(self,index):\n",
        "        frame = self.frameIndex[index]\n",
        "        if frame < 0:\n",
        "          X = torch.cat((torch.zeros(abs(frame)*40,dtype=torch.float64),torch.flatten(self.X[index - (12 - abs(frame)):index+13])),0)\n",
        "          Y = self.Y[index].long()\n",
        "        elif frame>0:\n",
        "          X = torch.cat((torch.flatten(self.X[index-12:index+(13-frame)]),torch.zeros(frame*40,dtype=torch.float64)),0)\n",
        "          Y = self.Y[index].long()\n",
        "        else:\n",
        "          X = torch.flatten(self.X[index-12:index+13])\n",
        "          Y = self.Y[index].long()\n",
        "        return X.float(),Y\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UyhQ5Sqmw9eN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# class MyDataset(data.Dataset):\n",
        "#     def __init__(self, X, Y):\n",
        "#         self.X = torch.from_numpy(np.vstack(X))\n",
        "#         self.Y = torch.from_numpy(np.vstack(np.array([np.expand_dims(i,axis=1) for i in Y]))).reshape(self.X.shape[0],)\n",
        "\n",
        "#     def __len__(self):\n",
        "#         self.data_ln = len(self.Y)\n",
        "#         return len(self.Y)\n",
        "\n",
        "#     def __getitem__(self,index):\n",
        "#         if index < 12:\n",
        "#           X = torch.cat((torch.zeros((12-index)*40,dtype=torch.float64),torch.flatten(self.X[0:index+13])),0)\n",
        "#           Y = self.Y[index].long()\n",
        "#         elif index >= (self.data_ln - 12):\n",
        "#           X = torch.cat((torch.flatten(self.X[index-12:self.data_ln]),torch.zeros((13 - (self.data_ln - index))*40,dtype=torch.float64)),0)\n",
        "#           Y = self.Y[index].long()\n",
        "#         else:\n",
        "#           X = torch.flatten(self.X[index-12:index+13])\n",
        "#           Y = self.Y[index].long()\n",
        "#         return X.float(),Y\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2DsD795daIQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MyDatasetTest(data.Dataset):\n",
        "    def __init__(self, X):\n",
        "        self.X = torch.from_numpy(np.vstack(X))\n",
        "        # self.Y = torch.from_numpy(np.vstack(np.array([np.expand_dims(i,axis=1) for i in Y]))).reshape(self.X.shape[0],)\n",
        "        self.frameIndex = dict()\n",
        "        counter = 0\n",
        "        for i in range(X.shape[0]):\n",
        "          for j in range(X[i].shape[0]):\n",
        "            if j < 12:\n",
        "              self.frameIndex[counter] = j - 12\n",
        "            elif j >= (X[i].shape[0] - 12):\n",
        "              self.frameIndex[counter] =  13 - (X[i].shape[0] - j)\n",
        "            else:\n",
        "              self.frameIndex[counter] = 0\n",
        "            counter = counter + 1 \n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.frameIndex)\n",
        "\n",
        "    def __getitem__(self,index):\n",
        "        frame = self.frameIndex[index]\n",
        "        if frame < 0:\n",
        "          X = torch.cat((torch.zeros(abs(frame)*40,dtype=torch.float64),torch.flatten(self.X[index - (12 - abs(frame)):index+13])),0)\n",
        "          # Y = self.Y[index].long()\n",
        "        elif frame>0:\n",
        "          X = torch.cat((torch.flatten(self.X[index-12:index+(13-frame)]),torch.zeros(frame*40,dtype=torch.float64)),0)\n",
        "          # Y = self.Y[index].long()\n",
        "        else:\n",
        "          X = torch.flatten(self.X[index-12:index+13])\n",
        "          # Y = self.Y[index].long()\n",
        "        return X.float()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZu74eRRdqZ0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# class MyDatasetTest(data.Dataset):\n",
        "#     def __init__(self, X):\n",
        "#         self.X = torch.from_numpy(np.vstack(X))\n",
        "\n",
        "#     def __len__(self):\n",
        "#         self.lengthofData = len(self.X)\n",
        "#         return len(self.X)\n",
        "\n",
        "#     def __getitem__(self,index):\n",
        "#         if index < 12:\n",
        "#           X = torch.cat((torch.zeros((12-index)*40,dtype=torch.float64),torch.flatten(self.X[0:index+13])),0)\n",
        "#         elif index >= (len(self.X) - 12):\n",
        "#           X = torch.cat((torch.flatten(self.X[index-12:len(self.X)]),torch.zeros((13 - (len(self.X) - index))*40,dtype=torch.float64)),0)\n",
        "#         else:\n",
        "#           X = torch.flatten(self.X[index-12:index+13])\n",
        "#         return X.float()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JnkttAeysVfT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Training\n",
        "train_dataset = MyDataset(data_train, data_train_label)\n",
        "\n",
        "train_loader_args = dict(shuffle=True, batch_size=128, num_workers=8, pin_memory=True) if cuda\\\n",
        "                    else dict(shuffle=True, batch_size=64)\n",
        "train_loader = data.DataLoader(train_dataset, **train_loader_args)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-U8zEaufeDNX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_dataset = MyDatasetTest(data_test)\n",
        "\n",
        "test_loader_args = dict(shuffle=False, batch_size=128, num_workers=8, pin_memory=True) if cuda\\\n",
        "                    else dict(shuffle=False, batch_size=1)\n",
        "test_loader = data.DataLoader(test_dataset, **test_loader_args)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZIY9-lsTs0A_",
        "colab_type": "code",
        "outputId": "9e1a24d7-4cdb-4124-9253-bdb71fd75e5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "testCounter = 0;\n",
        "for batch, (data,target) in enumerate(train_loader):\n",
        "  print(data.shape, target.shape)\n",
        "  testCounter = testCounter + 1\n",
        "  if testCounter == 15:\n",
        "    break"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([128, 1000]) torch.Size([128])\n",
            "torch.Size([128, 1000]) torch.Size([128])\n",
            "torch.Size([128, 1000]) torch.Size([128])\n",
            "torch.Size([128, 1000]) torch.Size([128])\n",
            "torch.Size([128, 1000]) torch.Size([128])\n",
            "torch.Size([128, 1000]) torch.Size([128])\n",
            "torch.Size([128, 1000]) torch.Size([128])\n",
            "torch.Size([128, 1000]) torch.Size([128])\n",
            "torch.Size([128, 1000]) torch.Size([128])\n",
            "torch.Size([128, 1000]) torch.Size([128])\n",
            "torch.Size([128, 1000]) torch.Size([128])\n",
            "torch.Size([128, 1000]) torch.Size([128])\n",
            "torch.Size([128, 1000]) torch.Size([128])\n",
            "torch.Size([128, 1000]) torch.Size([128])\n",
            "torch.Size([128, 1000]) torch.Size([128])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NC5hgwTa_GPJ",
        "colab_type": "code",
        "outputId": "dad6eb10-e431-4dc8-a12a-ae2130b86a41",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cuda"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K9gcWc_VxHKI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# SIMPLE MODEL DEFINITION\n",
        "class Simple_MLP(nn.Module):\n",
        "    def __init__(self, size_list):\n",
        "        super(Simple_MLP, self).__init__()\n",
        "        layers = []\n",
        "        self.size_list = size_list\n",
        "        # print(size_list)\n",
        "        # print(len(size_list) - 2)\n",
        "        for i in range(len(size_list) - 2):\n",
        "            layers.append(nn.Linear(size_list[i],size_list[i+1]))\n",
        "            layers.append(nn.BatchNorm1d(size_list[i+1]))\n",
        "            layers.append(nn.LeakyReLU())\n",
        "        layers.append(nn.Linear(size_list[-2], size_list[-1]))\n",
        "        self.net = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNZ3-AKL9Sm7",
        "colab_type": "code",
        "outputId": "6c785be6-525f-48c9-99f6-b0a3a4c6517b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "source": [
        "model = Simple_MLP([1000,2048,1024,1024,1024,1024,800,512,138])\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "device = torch.device(\"cuda\" if cuda else \"cpu\")\n",
        "model.to(device)\n",
        "print(model)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Simple_MLP(\n",
            "  (net): Sequential(\n",
            "    (0): Linear(in_features=1000, out_features=2048, bias=True)\n",
            "    (1): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): LeakyReLU(negative_slope=0.01)\n",
            "    (3): Linear(in_features=2048, out_features=1024, bias=True)\n",
            "    (4): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): LeakyReLU(negative_slope=0.01)\n",
            "    (6): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "    (7): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (8): LeakyReLU(negative_slope=0.01)\n",
            "    (9): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "    (10): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (11): LeakyReLU(negative_slope=0.01)\n",
            "    (12): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "    (13): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (14): LeakyReLU(negative_slope=0.01)\n",
            "    (15): Linear(in_features=1024, out_features=800, bias=True)\n",
            "    (16): BatchNorm1d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (17): LeakyReLU(negative_slope=0.01)\n",
            "    (18): Linear(in_features=800, out_features=512, bias=True)\n",
            "    (19): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (20): LeakyReLU(negative_slope=0.01)\n",
            "    (21): Linear(in_features=512, out_features=138, bias=True)\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6mEnYUbK9VnU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_epoch(model, train_loader, criterion, optimizer):\n",
        "    model.train()\n",
        "\n",
        "    running_loss = 0.0\n",
        "    \n",
        "    start_time = time.time()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):   \n",
        "        optimizer.zero_grad()   # .backward() accumulates gradients\n",
        "        data = data.to(device)\n",
        "        target = target.to(device) # all data & model on same device\n",
        "\n",
        "        outputs = model(data)\n",
        "        loss = criterion(outputs, target)\n",
        "        running_loss += loss.item()\n",
        "        if (batch_idx%10000) == 0:\n",
        "              print(batch_idx,' Running Loss ',running_loss)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    \n",
        "    end_time = time.time()\n",
        "    \n",
        "    running_loss /= len(train_loader)\n",
        "    print('Training Loss: ', running_loss, 'Time: ',end_time - start_time, 's')\n",
        "    return running_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4JD6vqqQ9ca6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test_model(model, test_loader, criterion):\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "\n",
        "        running_loss = 0.0\n",
        "        total_predictions = 0.0\n",
        "        correct_predictions = 0.0\n",
        "        output = []\n",
        "        counter = 0\n",
        "        for batch_idx, (data) in enumerate(test_loader):   \n",
        "            data = data.to(device)\n",
        "            # target = target.to(device)\n",
        "\n",
        "            outputs = model(data)\n",
        "\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            ansB = predicted.cpu().numpy()\n",
        "            for i in range(ansB.shape[0]):\n",
        "              output.append((counter,ansB[i]))\n",
        "              counter = counter + 1\n",
        "            # numpyPred = np.array(predicted.cpu)\n",
        "            # for i in range(numpyPred.shape[0]):\n",
        "            #   outPutList.append(counter,numpyPred[i])\n",
        "            #   counter = counter + 1\n",
        "            # total_predictions += target.size(0)\n",
        "            # correct_predictions += (predicted == target).sum().item()\n",
        "\n",
        "            # loss = criterion(outputs, target).detach()\n",
        "            # running_loss += loss.item()\n",
        "            \n",
        "\n",
        "        # running_loss /= len(test_loader)\n",
        "        # acc = (correct_predictions/total_predictions)*100.0\n",
        "        # print('Testing Loss: ', running_loss)\n",
        "        # print('Testing Accuracy: ', acc, '%')\n",
        "        # return running_loss, acc\n",
        "        return np.array(output)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CDmBamUa9lti",
        "colab_type": "code",
        "outputId": "b90612b8-547e-4225-8a2b-7a08f91aec92",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "source": [
        "n_epochs = 25\n",
        "Train_loss = []\n",
        "Test_loss = []\n",
        "Test_acc = []\n",
        "\n",
        "for i in range(n_epochs):\n",
        "    train_loss = train_epoch(model, train_loader, criterion, optimizer)\n",
        "    # test_model(model, test_loader, criterion)\n",
        "    Train_loss.append(train_loss)\n",
        "    #Test_loss.append(test_loss)\n",
        "    #Test_acc.append(test_acc)\n",
        "    print('='*20)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0  Running Loss  4.97443151473999\n",
            "1000  Running Loss  3386.9752066135406\n",
            "2000  Running Loss  6385.580970048904\n",
            "3000  Running Loss  9216.506766319275\n",
            "4000  Running Loss  11964.478477478027\n",
            "5000  Running Loss  14644.336750030518\n",
            "6000  Running Loss  17293.213108301163\n",
            "7000  Running Loss  19877.387897729874\n",
            "8000  Running Loss  22430.90770292282\n",
            "9000  Running Loss  24940.232793569565\n",
            "10000  Running Loss  27412.960919618607\n",
            "11000  Running Loss  29863.879643321037\n",
            "12000  Running Loss  32293.970700621605\n",
            "13000  Running Loss  34703.56318509579\n",
            "14000  Running Loss  37095.48234462738\n",
            "15000  Running Loss  39457.71322596073\n",
            "16000  Running Loss  41810.06712424755\n",
            "17000  Running Loss  44132.886035203934\n",
            "18000  Running Loss  46449.873013973236\n",
            "19000  Running Loss  48744.54637551308\n",
            "20000  Running Loss  51028.49230110645\n",
            "21000  Running Loss  53285.92122256756\n",
            "22000  Running Loss  55533.46846139431\n",
            "23000  Running Loss  57766.57511615753\n",
            "24000  Running Loss  59990.10120391846\n",
            "25000  Running Loss  62188.13167929649\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EGeEZQpFAaKO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ans = test_model(model, test_loader, criterion)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_6CPDL7nJQIC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ans.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YgvEAZ6kNaxd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "finalAns = pd.DataFrame(ans,columns=['id','label'])\n",
        "finalAns.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iWLIiUQtNkVi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "finalAns.to_csv('/content/hw1p2.csv',index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NuEsELA7v2DA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "finalAns.head(10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tyU8dmIz9ogX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.title('Training Loss')\n",
        "plt.xlabel('Epoch Number')\n",
        "plt.ylabel('Loss')\n",
        "plt.plot(Train_loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "66L-K9wic8BE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!kaggle competitions submit -c 11-785-s20-hw1p2 -f /content/hw1p2.csv -m \"New Submission\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xjh8RLav9_NX",
        "colab_type": "code",
        "outputId": "f7037e97-50b6-4642-fbb1-a102adf11647",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        }
      },
      "source": [
        "plt.title('Test Loss')\n",
        "plt.xlabel('Epoch Number')\n",
        "plt.ylabel('Loss')\n",
        "plt.plot(Test_loss)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f9d44cff9b0>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 183
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSWqcQSBJjTMIJKlxBoEkNe7/A29evn0KPSYJAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ds2OoU9y-CD0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "testing = torch.from_numpy(np.vstack(data_test)).shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7q8WSDvA8Z00",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model[testing]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I-x_eJxOLiOB",
        "colab_type": "code",
        "outputId": "0cc3e4eb-223c-4b05-b112-8b8518521fe4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "str(1)+','+str(2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1,2'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qhuV273iLl1v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "yoyo = []\n",
        "yoyo.append((1,2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7VySS7Y0MyWZ",
        "colab_type": "code",
        "outputId": "5808ccf2-cc98-45dd-a591-4718c00301fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "yoyo"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(1, 2)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jpf-ZBSzNBug",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "yoyo.append((3,4))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gvfkwDPLMy3o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tyty = np.array(yoyo)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0aHhjMn8M1cx",
        "colab_type": "code",
        "outputId": "5afb8e72-2043-4ba7-b035-622043788cf7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tyty.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TqyfUGpfM5Nr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "m = nn.Softmax(dim = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pbW2PX9bRSMV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input = torch.randn(2, 3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aa-yHi0dRVzQ",
        "colab_type": "code",
        "outputId": "7434f61f-67da-44c0-a9f3-15981b59bc51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "input\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.0927, -1.1937, -0.3873],\n",
              "        [-0.2803, -0.6666,  0.5635]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZAlPptaRWkY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "output = m(input)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "thtEzNdrRb1v",
        "colab_type": "code",
        "outputId": "8412d394-c446-422f-c141-8bccb34c8cd3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "output"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.7086, 0.2472, 0.0442],\n",
              "        [0.8346, 0.0762, 0.0892]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VwGRn9L_Rcn7",
        "colab_type": "code",
        "outputId": "bea19974-5ab1-49a4-c3af-61a06bec9e13",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "output"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.4814, 0.1601, 0.3585],\n",
              "        [0.2497, 0.1697, 0.5806]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1gQdaUVwRmiv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}